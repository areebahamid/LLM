# Student LLM Assistant

A real-time, deployable LLM assistant for students using RAG + LangChain + FastAPI + React frontend.

## üöÄ Features

- **Real-time AI Chat**: Powered by Ollama with local LLM inference
- **RAG (Retrieval-Augmented Generation)**: Enhanced responses using FAISS vector database
- **Modern UI/UX**: Beautiful React frontend with responsive design
- **FastAPI Backend**: High-performance API with async support
- **Student-Focused**: Optimized for educational content and academic queries
- **Deployable**: Ready for Vercel deployment

## üõ†Ô∏è Tech Stack

### Backend

- **FastAPI**: Modern, fast web framework
- **LangChain**: LLM orchestration and RAG implementation
- **Ollama**: Local LLM inference (supports various models)
- **FAISS**: Vector similarity search for RAG
- **Pydantic**: Data validation and serialization

### Frontend

- **React 18**: Modern React with hooks
- **TypeScript**: Type-safe development
- **Tailwind CSS**: Utility-first CSS framework
- **Vite**: Fast build tool and dev server
- **Axios**: HTTP client for API calls


